{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Transform Load (ETL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "-   Read Txt and CSV file types.\n",
    "-   Extract data from the above file types.\n",
    "-   Transform data.\n",
    "-   Save the transformed data in a ready-to-load format then load into an RDBMS (SQLite)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from sqlite3 import Error \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_connection(path):\n",
    "        connection = None\n",
    "        try: \n",
    "            connection = sqlite3.connect(path)\n",
    "            print('Connection to SQLite DB is successful')\n",
    "        except Error as e:\n",
    "            print(f\"The error '{e}' occured\")\n",
    "        return connection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection to SQLite DB is successful\n"
     ]
    }
   ],
   "source": [
    "connection = create_connection(\"C:\\\\Users\\sam\\ETL-Project\\SQL\\course.sqlite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_query(connection, query):\n",
    "        cursor = connection.cursor()\n",
    "        try:\n",
    "            cursor.execute(query)\n",
    "            connection.commit()\n",
    "            print(\"Query executed sucessfully\")\n",
    "        except Error as e:\n",
    "            print(f\"The error '{e}' occured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_course_table = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS course(\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    course_id INTEGER,\n",
    "    title TEXT NOT NULL,\n",
    "    description TEXT,\n",
    "    programming_language TEXT\n",
    ");\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query executed sucessfully\n"
     ]
    }
   ],
   "source": [
    "execute_query(connection,create_course_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_rating_table = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS ratings(\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    course_id INTEGER,\n",
    "    rating INTEGER,\n",
    "    user_id INTERGER NOT NULL,\n",
    "    FOREIGN KEY (course_id) REFERENCES course(id)\n",
    ");\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query executed sucessfully\n"
     ]
    }
   ],
   "source": [
    "execute_query(connection,create_rating_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_course = \"\"\"\n",
    "INSERT INTO\n",
    "course(course_id, title, description,programming_language)\n",
    "VALUES\n",
    "(1, 'Machine Learning with Apache Spark', 'Spark is a powerful, general purpose tool for working with Big Data. Spark transparently handles the distribution of compute tasks across a cluster. This means that operations are fast, but it also allows you to focus on the analysis rather than worry about technical details. In this course you''ll learn how to get data into Spark and then delve into the three fundamental Spark Machine Learning algorithms: Linear Regression, Logistic Regression/Classifiers, and creating pipelines. Along the way you''ll analyse a large dataset of flight delays and spam text messages. With this background you''ll be ready to harness the power of Spark and apply it on your own Machine Learning projects!', 'python'),\n",
    "(2, 'Financial Analytics in Spreadsheets', 'Monitoring the evolution of traded assets is key in finance. In this course, you will learn how to build a graphical dashboard with spreadsheets to track the performance of financial securities. You will focus on historical prices and dividends of the hypothetical stock ABC. You will learn how to visualize its prices, how to measure essential reward and risk indicators, and see if your investment in ABC outperformed a benchmark index. At the end of the course, you should be able to use spreadsheets to build great monitoring tools used by traders and financial analysts in their day-to-day business life!', 'spreadsheets'),\n",
    "(3, 'Intermediate R', 'The intermediate R course is the logical next stop on your journey in the R programming language. In this R training you will learn about conditional statements, loops and functions to power your own R scripts. Next, you can make your R code more efficient and readable using the apply functions. Finally, the utilities chapter gets you up to speed with regular expressions in the R programming language, data structure manipulations and times and dates. This R tutorial will allow you to learn R and take the next step in advancing your overall knowledge and capabilities while programming in R.', 'r'),\n",
    "(4, 'Data Visualization with ggplot2 (Part 2)', 'This ggplot2 tutorial builds on your knowledge from the first course to produce meaningful explanatory plots. We''ll explore the last four optional layers. Statistics will be calculated on the fly and weâ€™ll see how Coordinates and Facets aid in communication. Publication quality plots will be produced directly in R using the Themes layer. Weâ€™ll also discuss details on data visualization best practices with ggplot2 to help make sure you have a sound understanding of what works and why. By the end of the course, youâ€™ll have all the tools needed to make a custom plotting function to explore a large data set, combining statistics and excellent visuals.', 'r'),\n",
    "(5, 'Fraud Detection in R', 'The Association of Certified Fraud Examiners estimates that fraud costs organizations worldwide $3.7 trillion a year and that a typical company loses five percent of annual revenue due to fraud. Fraud attempts are expected to even increase further in future, making fraud detection highly necessary in most industries. This course will show how learning fraud patterns from historical data can be used to fight fraud. Some techniques from robust statistics and digit analysis are presented to detect unusual observations that are likely associated with fraud. Two main challenges when building a supervised tool for fraud detection are the imbalance or skewness of the data and the various costs for different types of misclassification. We present techniques to solve these issues and focus on artificial and real datasets from a wide variety of fraud applications.', 'r'),\n",
    "(6, 'Joining Data in SQL', 'Now that you''ve learned the basics of SQL in our <a href=\"https://www.datacamp.com/courses/intro-to-sql-for-data-science\">Intro to SQL for Data Science</a> course, it''s time to supercharge your queries using joins and relational set theory! In this course you''ll learn all about the power of joining tables while exploring interesting features of countries and their cities throughout the world. You will master inner and outer joins, as well as self-joins, semi-joins, anti-joins and cross joins - fundamental tools in any PostgreSQL wizard''s toolbox. You''ll fear set theory no more, after learning all about unions, intersections, and except clauses through easy-to-understand diagrams and examples. Lastly, you''ll be introduced to the challenging topic of subqueries. You will see a visual perspective to grasp the ideas throughout the course using the mediums of Venn diagrams and other linking illustrations.', 'sql'),\n",
    "(7, 'Introduction to Python', 'Python is a general-purpose programming language that is becoming more and more popular for doing data science. Companies worldwide are using Python to harvest insights from their data and get a competitive edge. Unlike any other Python tutorial, this course focuses on Python specifically for data science. In our Intro to Python class, you will learn about powerful ways to store and manipulate data as well as cool data science tools to start your own analyses. Enter DataCampâ€™s online Python curriculum.', 'python'),\n",
    "(8, 'Bayesian Modeling with RJAGS', 'The Bayesian approach to statistics and machine learning is logical, flexible, and intuitive. In this course, you will engineer and analyze a family of foundational, generalizable Bayesian models. These range in scope from fundamental one-parameter models to intermediate multivariate & generalized linear regression models. The popularity of such Bayesian models has grown along with the availability of computing resources required for their implementation. You will utilize one of these resources - the rjags package in R. Combining the power of R with the JAGS (Just Another Gibbs Sampler) engine, rjags provides a framework for Bayesian modeling, inference, and prediction.', 'r'),\n",
    "(9, 'Credit Risk Modeling in R', '<p>This hands-on-course with real-life credit data will teach you how to model credit risk by using logistic regression and decision trees in R.</p><p>Modeling credit risk for both personal and company loans is of major importance for banks. The probability that a debtor will default is a key component in getting to a measure for credit risk. While other models will be introduced in this course as well, you will learn about two model types that are often used in the credit scoring context; logistic regression and decision trees. You will learn how to use them in this particular context, and how these models are evaluated by banks.</p>', 'r'),\n",
    "(10, 'Experimental Design in R', 'Experimental design is a crucial part of data analysis in any field, whether you work in business, health or tech. If you want to use data to answer a question, you need to design an experiment! In this course you will learn about basic experimental design, including block and factorial designs, and commonly used statistical tests, such as the t-tests and ANOVAs. You will use built-in R data and real world datasets including the CDC NHANES survey, SAT Scores from NY Public Schools, and Lending Club Loan Data. Following the course, you will be able to design and analyze your own experiments!', 'r'),\n",
    "(11, 'Supervised Learning in R: Classification', 'This beginner-level introduction to machine learning covers four of the most common classification algorithms. You will come away with a basic understanding of how each algorithm approaches a learning task, as well as learn the R functions needed to apply these tools to your own work.', 'r'),\n",
    "(12, 'Visualizing Time Series Data in R', 'As the saying goes, â€œA chart is worth a thousand wordsâ€. This is why visualization is the most used and powerful way to get a better understanding of your data. After this course you will have a very good overview of R time series visualisation capabilities and you will be able to better decide which model to choose for subsequent analysis. You will be able to also convey the message you want to deliver in an efficient and beautiful way.', 'r'),\n",
    "(13, 'Equity Valuation in R', 'How do we know when a stock is cheap or expensive? To do this, we need to compare the stock''s price with its value. The price of the stock can be obtained by looking at various public sources, such as Yahoo Finance or Google Finance. The value of the stock though is much harder to identify. Every investor has to form his or her valuation of the stock. In this course, you will learn the fundamentals of valuing stocks using present value approaches, such as free cash flow to equity and dividend discount models, and valuation multiples. By the end of this course, you will be able to build your own valuation models.', 'r'),\n",
    "(14, 'Intro to Portfolio Risk Management in Python', 'This course will teach you how to evaluate basic portfolio risk and returns like a quantitative analyst on Wall Street. This is the most critical step towards being able to fully automate your portfolio construction and management processes. Discover what factors are driving your portfolio returns, construct market-cap weighted equity portfolios, and learn how to forecast and hedge market risk via scenario generation.', 'python'),\n",
    "(15, 'Data-Driven Decision Making in SQL', 'In this course, you will learn how to use SQL to support decision making. It is based on a case study about an online movie rental company with a database about customer information, movie ratings, background information on actors and more. You will learn to apply SQL queries to study for example customer preferences, customer engagement, and sales development. This course also covers SQL extensions for online analytical processing (OLAP), which makes it easier to obtain key insights from multidimensional aggregated data.', 'sql'),\n",
    "(16, 'Intermediate Functional Programming with purrr', 'Have you ever been wondering what the purrr description (â€œA functional programming toolkit for Râ€) refers to? Then, youâ€™ve come to the right place! This course will walk you through the functional programming part of purrr - in other words, you will learn how to take full advantage of the flexibility offered by the .f in map(.x, .f) to iterate other lists, vectors and data.frame with a robust, clean, and easy to maintain code. During this course, you will learn how to write your own mappers (or lambda functions), and how to use predicates and adverbs. Finally, this new knowledge will be applied to a use case, so that youâ€™ll be able to see how you can use this newly acquired knowledge on a concrete example of a simple nested list, how to extract, keep or discard elements, how to compose functions to manipulate and parse results from this list, how to integrate purrr workflow inside other functions, how to avoid copy and pasting with purrr functional tools.', 'r'),\n",
    "(17, 'Analyzing US Census Data in Python', 'Data scientists in diverse fields, from marketing to public health to civic hacking, need to work with demographic and socioeconomic data. Government census agencies offer richly detailed, high-quality datasets, but the number of variables and intricacies of administrative geographies (what is a Census tract anyway?) can make approaching this goldmine a daunting process. This course will introduce you to the Decennial Census and the annual American Community Survey, and show you where to find data on household income, commuting, race, family structure, and other topics that may interest you. You will use Python to request this data using the Census API for large and small geographies. You will manipulate the data using pandas, and create derived data such as a measure of segregation. You will also get a taste of the mapping capabilities of geopandas.', 'python'),\n",
    "(18, 'Network Analysis in Python (Part 1)', 'From online social networks such as Facebook and Twitter to transportation networks such as bike sharing systems, networks are everywhere, and knowing how to analyze this type of data will open up a new world of possibilities for you as a Data Scientist. This course will equip you with the skills to analyze, visualize, and make sense of networks. You''ll apply the concepts you learn to real-world network data using the powerful NetworkX library. With the knowledge gained in this course, you''ll develop your network thinking skills and be able to start looking at your data with a fresh perspective!', 'python'),\n",
    "(19, 'Introduction to Databases in Python', 'In this Python SQL course, you''ll learn the basics of using Structured Query Language (SQL) with Python. This will be useful since whether you like it or not, databases are ubiquitous and, as a data scientist, you''ll need to interact with them constantly. The Python SQL toolkit SQLAlchemy provides an accessible and intuitive way to query, build & write to SQLite, MySQL and Postgresql databases (among many others), all of which you will encounter in the daily life of a data scientist.', 'python'),\n",
    "(20, 'Introduction to Git for Data Science', 'Version control is one of the power tools of programming. It allows you to keep track of what you did when, undo any changes you have decided you don''t want, and collaborate at scale with other people. This course will introduce you to Git, a modern version control tool that is very popular with data scientists and software developers alike, and show you how it can help you get more done in less time and with less pain.', 'shell'),\n",
    "(21, 'Supply Chain Analytics in Python', 'Supply Chain Analytics transforms supply chain activities from guessing, to ones that makes decision using data. An essential tool in Supply Chain Analytics is using optimization analysis to assist in decision making. According to Deloitte, 79% of organizations with high performing supply chains achieve revenue growth that is significantly above average. This course will introduce you to PuLP, a Linear Program optimization modeler written in Python. Using PuLP, the course will show you how to formulate and answer Supply Chain optimization questions such as where a production facility should be located, how to allocate production demand across different facilities, and more. We will explore the results of the models and their implications through sensitivity and simulation testing. This course will help you position yourself to improve the decision making of a supply chain by leveraging the power of Python and PuLP.', 'python'),\n",
    "(22, 'Importing & Cleaning Data in R: Case Studies', 'Running exciting analyses on interesting datasets is the dream of every data scientist. But first, some importing and cleaning must be done. In this series of four case studies, you''ll revisit key concepts from our courses on importing and cleaning data in R.', 'r'),\n",
    "(91, 'Importing Data in R (Part 2)', '<p>In this second part to <a href=\"https://www.datacamp.com/courses/importing-data-in-r-part-1\">Importing Data in R</a>, you will take a deeper dive into the wide range of data formats out there. More specifically, you''ll learn how to import data from relational databases and how to import and work with data coming from the web. Finally, you''ll get hands-on experience with importing data from statistical software packages such SAS, STATA and SPSS.</p>', 'r'),\n",
    "(23, 'GARCH Models in R', 'Are you curious about the rhythm of the financial market''s heartbeat? Do you want to know when a stable market becomes turbulent? In this course on GARCH models you will learn the forward looking approach to balancing risk and reward in financial decision making. The course gradually moves from the standard normal GARCH(1,1) model to more advanced volatility models with a leverage effect, GARCH-in-mean specification and the use of the skewed student t distribution for modelling asset returns. Applications on stock and exchange rate returns include portfolio optimization, rolling sample forecast evaluation, value-at-risk forecasting and studying dynamic covariances.', 'r'),\n",
    "(24, 'Nonlinear Modeling in R with GAMs', 'Generalized Additive Models are a powerful tool for both prediction and inference. More flexible than linear models, and more understandable than black-box methods, GAMs model relationships in data as nonlinear functions that are highly adaptable to different types of data and data science problems. In this course, you''ll learn how GAMs work and how to construct them with the popular <strong>mgcv</strong> package. You''ll learn how to interpret, explain and visualize your model results, and how to diagnose and fix model problems. You''ll work with data sets that will show you how to apply GAMs to a variety of situations: automobile performance data for building mixed linear and nonlinear models, soil pollution data for building geospatial models, and consumer purchasing data for classification and prediction. By the end of this course, you''ll have a toolbox for solving many data science problems.', 'r'),\n",
    "(25, 'Machine Learning with Tree-Based Models in R', 'In this course you''ll learn how to work with tree-based models in R. This course covers everything from using a single tree for regression or classification to more advanced ensemble methods. You''ll learn to implement bagged trees, Random Forests, and boosted trees using the Gradient Boosting Machine, or GBM. These powerful techinques will allow you to create high performance regression and classification models for your data.', 'r'),\n",
    "(26, 'Introduction to Seaborn', 'Seaborn is a powerful Python library that makes it easy to create informative and attractive visualizations. This course provides an introduction to Seaborn and teaches you how to visualize your data using plots such as scatter plots, box plots, and bar plots. Youâ€™ll do this while exploring survey responses about student hobbies and the factors that are associated with academic success. Youâ€™ll also learn about some of Seabornâ€™s advantages as a statistical visualization tool, such as how it automatically calculates confidence intervals. By the end of the course, you will be able to use Seaborn in a variety of situations to explore your data and effectively communicate the results of your data analyses to others.', 'python'),\n",
    "(27, 'Bayesian Regression Modeling with rstanarm', 'Bayesian estimation offers a flexible alternative to modeling techniques where the inferences depend on p-values. In this course, youâ€™ll learn how to estimate linear regression models using Bayesian methods and the rstanarm package. Youâ€™ll be introduced to prior distributions, posterior predictive model checking, and model comparisons within the Bayesian framework. Youâ€™ll also learn how to use your estimated model to make predictions for new data.', 'r'),\n",
    "(28, 'Python for Spreadsheet Users', 'Are you looking for a better solution than the one youâ€™ve built in a spreadsheet? If so, then Python for Spreadsheet Users is a great introduction to the Python language, and will put you on the right path towards automating repetitive work, diving deeper into your data, and widening the scope of what you are capable of accomplishing. Throughout the course, weâ€™ll draw parallels to common spreadsheet functions and techniques, so youâ€™ll always have a familiar reference point as you dive head first into Python.', 'python'),\n",
    "(29, 'Spatial Statistics in R', 'Everything happens somewhere, and increasingly the place where all these things happen is being recorded in a database. There is some truth behind the oft-repeated statement that 80% of data have a spatial component. So what can we do with this spatial data? Spatial statistics, of course! Location is an important explanatory variable in so many things - be it a disease outbreak, an animal''s choice of habitat, a traffic collision, or a vein of gold in the mountains - that we would be wise to include it whenever possible. This course will start you on your journey of spatial data analysis. You''ll learn what classes of statistical problems present themselves with spatial data, and the basic techniques of how to deal with them. You''ll see how to look at a mess of dots on a map and bring out meaningful insights.', 'r'),\n",
    "(30, 'Fraud Detection in Python', 'A typical organization loses an estimated 5% of its yearly revenue to fraud. In this course, you will learn how to fight fraud by using data. For example, you''ll learn how to apply supervised learning algorithms to detect fraudulent behavior similar to past ones, as well as unsupervised learning methods to discover new types of fraud activities. Moreover, in fraud analytics you often deal with highly imbalanced datasets when classifying fraud versus non-fraud, and during this course you will pick up some techniques on how to deal with that. The course provides a mix of technical and theoretical insights and shows you hands-on how to practically implement fraud detection models. In addition, you will get tips and advice from real-life experience to help you prevent making common mistakes in fraud analytics.', 'python'),\n",
    "(31, 'Introduction to R for Finance', 'Learning R can be intimidating, especially without concrete examples you might see in the real world. In this finance oriented introduction to R, you will learn essential data structures such as lists and data frames and have the chance to apply that knowledge directly to financial examples. By the end of the course, you will feel comfortable with the basics of manipulating your data to perform financial analysis in R.', 'r'),\n",
    "(32, 'Intermediate Python for Data Science', 'The intermediate python course is crucial to your data science curriculum. Learn to visualize real data with matplotlib''s functions and get to know new data structures such as the dictionary and the Pandas DataFrame. After covering key concepts such as boolean logic, control flow and loops in Python, you''re ready to blend together everything you''ve learned to solve a case study using hacker statistics.', 'python'),\n",
    "(33, 'Introduction to Matplotlib', 'A picture is worth a thousand words. Visualizing data in plots and figures exposes the underlying patterns in the data and provides insights. Good visualizations also help you to communicate about your data with others. So good visualizations are useful both to data analysts and to other consumers of the data. In this course, you will learn how to use Matplotlib, a powerful Python data visualization library. Matplotlib provides the building blocks to create rich visualizations of many different kinds of datasets. You will learn how to create different kinds of visualizations for different kinds of data and how to customize, automate, and share these visualizations.', 'python'),\n",
    "(34, 'Big Data Fundamentals via PySpark', 'There''s been a lot of buzz about Big Data over the past few years, and it''s finally become mainstream for many companies. But what is this Big Data? This course covers the fundamentals of Big Data via PySpark. Spark is â€œlightning fast cluster computing\" framework for Big Data. It provides a general data processing platform engine and lets you run programs up to 100x faster in memory, or 10x faster on disk, than Hadoop. Youâ€™ll use PySpark, a Python package for spark programming and its powerful, higher-level libraries such as SparkSQL, MLlib (for machine learning), etc., to interact with works of William Shakespeare, analyze Fifa football 2018 data and perform clustering of genomic datasets. At the end of this course, you will gain an in-depth understanding of PySpark and itâ€™s application to general Big Data analysis.', 'python'),\n",
    "(35, 'Interactive Data Visualization with rbokeh', 'Data visualization is an integral part of the data analysis process. This course will get you introduced to rbokeh: a visualization library for interactive web-based plots. You will learn how to use rbokeh layers and options to create effective visualizations that carry your message and emphasize your ideas. We will focus on the two main pieces of data visualization: wrangling data in the appropriate format as well as employing the appropriate visualization tools, charts and options from rbokeh.', 'r'),\n",
    "(36, 'Importing Data in Python (Part 1)', 'As a Data Scientist, on a daily basis you will need to clean data, wrangle and munge it, visualize it, build predictive models and interpret these models. Before doing any of these, however, you will need to know how to get data into Python. In this course, you''ll learn the many ways to import data into Python: (i) from flat files such as .txts and .csvs; (ii) from files native to other software such as Excel spreadsheets, Stata, SAS and MATLAB files; (iii) from relational databases such as SQLite & PostgreSQL.', 'python'),\n",
    "(37, 'Writing Efficient R Code', 'The beauty of R is that it is built for performing data analysis. The downside is that sometimes R can be slow, thereby obstructing our analysis. For this reason, it is essential to become familiar with the main techniques for speeding up your analysis, so you can reduce computational time and get insights as quickly as possible.', 'r'),\n",
    "(38, 'Visualizing Big Data with Trelliscope', 'Having honed your visualization skills by learning ggplot2, it''s now time to tackle larger datasets. In this course, you will learn several techniques for visualizing big data, with particular focus on the scalable visualization technique of faceting. You will learn how to put this technique into action using the Trelliscope approach as implemented in the trelliscopejs R package. Trelliscope plugs seamlessly into standard R workflows and produces interactive visualizations that allow you to visually explore your data in detail. By the end of this course, you will be able to easily create interactive exploratory displays of large datasets that will help you and your colleagues gain new insights into your data.', 'r'),\n",
    "(39, 'Parallel Computing with Dask', 'Python is now well established as a major platform for data analysis and data science. For many data scientists, the largest limitation of Python is that all data must fit into the resident memory of the available workstation. Further, traditionally, Python has only been able to utilize one CPU. Data scientists constantly ask, \"How can I read and process large amounts of data?\" and \"How can I make use of more computational processing resources?\" This course will introduce you to Dask, a flexible parallel computing library for analytic computing. With Dask, you will be able to take the Python workflows you currently have and easily scale them up to large datasets on your workstation without the need to migrate to a distributed computing environment.\n",
    "', 'python'),\n",
    "(40, 'Machine Learning for Finance in Python', 'Time series data is all around us; some examples are the weather, human behavioral patterns as consumers and members of society, and financial data. In this course, you''ll learn how to calculate technical indicators from historical stock data, and how to create features and targets out of the historical stock data. You''ll understand how to prepare our features for linear models, xgboost models, and neural network models. We will then use linear models, decision trees, random forests, and neural networks to predict the future price of stocks in the US markets. You will also learn how to evaluate the performance of the various models we train in order to optimize them, so our predictions have enough accuracy to make a stock trading strategy profitable.', 'python'),\n",
    "(41, 'Defensive R Programming', 'Writing R scripts is easy. Writing good R code is hard. In this course, we''ll discuss defensive programming - a set of standard techniques that will help reduce bugs and aid working in teams. We examine techniques for avoiding common errors and also how to handle the inevitable error that arises in our code. The course will conclude looking at when to make the transition from script to project to package.', 'r'),\n",
    "(42, 'Conda Essentials', 'Software is constantly evolving, so data scientists need a way to update the software they are using without breaking things that already work. Conda is an open source, cross-platform tool for managing packages and working environments for many different programming languages. This course explains how to use its core features to manage your software so that you and your colleagues can reproduce your working environments reliably with minimum effort.', 'shell'),\n",
    "(43, 'Writing Efficient Python Code', 'As a Data Scientist, the majority of your time should be spent gleaning actionable insights from data -- not waiting for your code to finish running. Writing efficient Python code can help reduce runtime and save computational resources, ultimately freeing you up to do the things you love as a Data Scientist. In this course, you''ll learn how to use Python''s built-in data structures, functions, and modules to write cleaner, faster, and more efficient code. We''ll explore how to time and profile code in order to find bottlenecks. Then, you''ll practice eliminating these bottlenecks, and other bad design patterns, using Python''s Standard Library, NumPy, and pandas. After completing this course, you''ll have the necessary tools to start writing efficient Python code!', 'python'),\n",
    "(44, 'Introduction to Data Science in Python', 'Begin your journey into Data Science! Even if you''ve never written a line of code in your life, you''ll be able to follow this course and witness the power of Python to perform Data Science. You''ll use data to solve the mystery of Bayes, the kidnapped Golden Retriever, and along the way you''ll become familiar with basic Python syntax and popular Data Science modules like Matplotlib (for charts and graphs) and Pandas (for tabular data).', 'python'),\n",
    "(45, 'Multiple and Logistic Regression', 'In this course you''ll take your skills with simple linear regression to the next level. By learning multiple and logistic regression techniques you will gain the skills to model and predict both numeric and categorical outcomes using multiple input variables. You''ll also learn how to fit, visualize, and interpret these models. Then you''ll apply your skills to learn about Italian restaurants in New York City!', 'r'),\n",
    "(46, 'Designing and Analyzing Clinical Trials in R', 'Clinical trials are scientific experiments that are conducted to assess whether treatments are effective and safe. They are used by a variety of organizations, including pharmaceutical companies for drug development. Biostatisticians play a key role in ensuring the success of a clinical trial. In this course you will gain an overview of the important principles and a practical introduction to commonly used statistical analyses. This course would be valuable for data analysts, medical students, clinicians, medical researchers and others interested in learning about the design and analysis of clinical trials.', 'r'),\n",
    "(47, 'Foundations of Inference', 'One of the foundational aspects of statistical analysis is inference, or the process of drawing conclusions about a larger population from a sample of data. Although counter intuitive, the standard practice is to attempt to disprove a research claim that is not of interest. For example, to show that one medical treatment is better than another, we can assume that the two treatments lead to equal survival rates only to then be disproved by the data. Additionally, we introduce the idea of a p-value, or the degree of disagreement between the data and the hypothesis. We also dive into confidence intervals, which measure the magnitude of the effect of interest (e.g. how much better one treatment is than another).', 'r'),\n",
    "(48, 'Data Manipulation in R with data.table', 'The data.table package provides a high-performance version of base R''s data.frame with syntax and feature enhancements for ease of use, convenience and programming speed. This course shows you how to create, subset, and manipulate data.tables. You''ll also learn about the database-inspired features of data.tables, including built-in groupwise operations. The course concludes with fast methods of importing and exporting tabular text data such as CSV files. Upon completion of the course, you will be able to use data.table in R for a more efficient manipulation and analysis process. Throughout the course you''ll explore the San Francisco Bay Area bike share trip dataset from 2014.', 'r'),\n",
    "(49, 'Marketing Analytics in R: Statistical Modeling', 'This is your chance to dive into the worlds of marketing and business analytics using R. Day by day, there are a multitude of decisions that companies have to face. With the help of statistical models, you''re going to be able to support the business decision-making process based on data, not your gut feeling. Let us show you what a great impact statistical modeling can have on the performance of businesses. You''re going to learn about and apply strategies to communicate your results and help them make a difference.', 'r'),\n",
    "(50, 'Machine Learning Toolbox', 'Machine learning is the study and application of algorithms that learn from and make predictions on data. From search results to self-driving cars, it has manifested itself in all areas of our lives and is one of the most exciting and fast growing fields of research in the world of data science. This course teaches the big ideas in machine learning: how to build and evaluate predictive models, how to tune them for optimal performance, how to preprocess data for better results, and much more. The popular <code>caret</code> R package, which provides a consistent interface to all of R''s most powerful machine learning facilities, is used throughout the course.', 'r'),\n",
    "(51, 'Data Manipulation in R with dplyr', 'In this interactive tutorial, you will learn how to perform sophisticated dplyr techniques to carry out your data manipulation with R. First you will master the five verbs of R data manipulation with dplyr: select, mutate, filter, arrange and summarise. Next, you will learn how you can chain your dplyr operations using the pipe operator of the magrittr package. In the final section, the focus is on practicing how to subset your data using the group_by function, and how you can access data stored outside of R in a database. All said and done, you will be familiar with data manipulation tools and techniques that will allow you to efficiently manipulate data.', 'r'),\n",
    "(52, 'Feature Engineering for NLP in Python', 'In this course, you will learn techniques that will allow you to extract useful information from text and process them into a format suitable for applying ML models. More specifically, you will learn about POS tagging, named entity recognition, readability scores, the n-gram and tf-idf models, and how to implement them using scikit-learn and spaCy. You will also learn to compute how similar two documents are to each other. In the process, you will predict the sentiment of movie reviews and build movie and Ted Talk recommenders. Following the course, you will be able to engineer critical features out of any text and solve some of the most challenging problems in data science!', 'python'),\n",
    "(53, 'Interactive Data Visualization with plotly in R', 'Interactive graphics allow you to manipulate plotted data to gain further insight. As an example, an interactive graphic would allow you to zoom in on a subset of your data without the need to create a new plot. In this course, you will learn how to create and customize interactive graphics in plotly using the R programming language. Along the way, you will review data visualization best practices and be introduced to new plot types such as scatterplot matrices and binned scatterplots.', 'r'),\n",
    "(54, 'Improving Query Performance in SQL Server', 'A mission critical assignment is depending on your SQL coding skills. Youâ€™ve been given some code to fix. It is giving the results you need but itâ€™s running too slow, and itâ€™s poorly formatted making it hard to read. The deadline is tomorrow. Youâ€™ll need to reformat the code and try different methods to improve performance. The pressure is on!!! In this course weâ€™ll be using SQL on real world datasets, from sports and geoscience, to look at good coding practices and different ways how we can can improve the performance of queries to achieve the same outcome.', 'sql'),\n",
    "(55, 'Inference for Linear Regression', 'Previously, you learned the fundamentals of both statistical inference and linear models; now, the next step is to put them together. This course gives you a chance to think about how different samples can produce different linear models, where your goal is to understand the underlying population model. From the estimated linear model, you will learn how to create interval estimates for the effect size as well as how to determine if the effect is significant. Prediction intervals for the response variable will be contrasted with estimates of the average response. Throughout the course, you''ll gain more practice with the dplyr and ggplot2 packages, and you will learn about the broom package for tidying models; all three packages are invaluable in data science.', 'r'),\n",
    "(56, 'Extreme Gradient Boosting with XGBoost', 'Do you know the basics of supervised learning and want to learn to use state-of-the-art models on real-world datasets? Gradient boosting is currently one of the most popular techniques for efficient modeling of tabular datasets of all sizes. XGboost is a very fast, scalable implementation of gradient boosting that has taken data science by storm, with models using XGBoost regularly winning many online data science competitions and used at scale across different industries. In this course, you''ll learn how to use this powerful library alongside pandas and scikit-learn to build and tune supervised learning models. You''ll work with real-world datasets to solve classification as well as regression problems.', 'python'),\n",
    "(57, 'Statistical Modeling in R (Part 2)', '<i>Statistical Modeling in R</i> is a multi-part course designed to get you up to speed with the most important and powerful methodologies in statistics. In <i>Part 2</i>, we''ll take a look at effect size and interaction, the concepts of total and partial change, sampling variability and mathematical transforms, and the implications of something called collinearity. This course has been written from scratch, specifically for DataCamp users. As you''ll see, by using computing and concepts from machine learning, we''ll be able to leapfrog many of the marginal and esoteric topics encountered in traditional ''regression'' courses.', NULL),\n",
    "(58, 'Introduction to Text Analysis in R', 'From social media to product reviews, text is an increasingly important type of data across applications, including in marketing analytics. In many instances, text is replacing other forms of unstructured data due to how inexpensive and current it is. However, to take advantage of everything that text has to offer, you need to know how to think about, clean, summarize, and model text. In Introduction to Text Analysis in R, you will use the latest tidy tools to quickly and easily get started with text. You will learn how to wrangle and visualize text, perform sentiment analysis, and run and interpret topic models.', 'r'),\n",
    "(59, 'Visualizing Geospatial Data in Python', 'One of the most important tasks of a data scientist is to understand the relationships between their data''s physical location and their geographical context. In this course you''ll be learning to make attractive visualizations of geospatial data with the GeoPandas package. You will learn to spatially join datasets, linking data to context. Finally you will learn to overlay geospatial data to maps to add even more spatial cues to your work. You will use several datasets from the City of Nashville''s open data portal to find out where the chickens are in Nashville, which neighborhood has the most public art, and more!', 'python'),\n",
    "(60, 'Data Science for Managers', 'What is data science and how can you use it to strengthen your organization? This course will teach you about the skills you need on your data team, and how you can structure that team to meet your organization''s needs. Data is everywhere! This course will provide you with an understanding of data sources your company can use and how to store that data. You''ll also discover ways to analyze and visualize your data through dashboards and A/B tests. To wrap up the course, we''ll discuss exciting topics in machine learning, including clustering, time series prediction, natural language processing (NLP), deep learning, and explainable AI! Along the way, you''ll learn about a variety of real-world applications of data science and gain a better understanding of these concepts through practical exercises.', 'r'),\n",
    "(61, 'Manipulating Time Series Data in R: Case Studies', 'This follow-up course on manipulating time series data in R does not cover new data manipulation concepts. Instead, you will strengthen your knowledge of the topics covered in Manipulating Time Series Data in R with xts & zoo using new exercises and interesting datasets.\n",
    "', 'r'),\n",
    "(62, 'Intermediate Spreadsheets for Data Science', 'This course will expand your Google Sheets vocabulary. You''ll dive deeper into data types, practice manipulating numeric and logical data, explore missing data and error types, and calculate some summary statistics. As you go, you''ll explore datasets on 100m sprint world records, asteroid close encounters, benefit claims, and butterflies.', 'spreadsheets'),\n",
    "(63, 'Human Resources Analytics in R: Predicting Employee Churn', 'Organizational growth largely depends on staff retention. Losing employees frequently impacts the morale of the organization and hiring new employees is more expensive than retaining existing ones. Good news is that organizations can increase employee retention using data-driven intervention strategies. This course focuses on data acquisition from multiple HR sources, exploring and deriving new features, building and validating a logistic regression model, and finally, show how to calculate ROI for a potential retention strategy. ', 'r'),\n",
    "(64, 'Importing Data in R (Part 1)', '<p>Importing data into R to start your analysesâ€”it should be the easiest step. Unfortunately, this is almost never the case. Data come in all sorts of formats, ranging from CSV and text files and statistical software files to databases and HTML data. Knowing which approach to use is key to getting started with the actual analysis.</p><p>In this course, you will get started with learning how to read CSV and text files in R. You will then cover the readr and data.table packages to easily and efficiently import flat file data. After that you will learn how to read XLS files in R using readxl and gdata.</p>', 'r'),\n",
    "(65, 'Foundations of Functional Programming with purrr', 'Lists can be difficult to both understand and manipulate, but they can pack a ton of information and are very powerful. In this course, you will learn to easily extract, summarize, and manipulate lists and how to export the data to your desired object, be it another list, a vector, or even something else! Throughout the course, you will work with the purrr package and a variety of datasets from the repurrrsive package, including data from Star Wars and Wes Anderson films and data collected about GitHub users and GitHub repos. Following this course, your list skills will be purrrfect!', 'r'),\n",
    "(66, 'Visualizing Time Series Data in Python', 'Time series data is omnipresent in the field of Data Science. Whether it is analyzing business trends, forecasting company revenue or exploring customer behavior, every data scientist is likely to encounter time series data at some point during their work. To get you started on working with time series data, this course will provide practical knowledge on visualizing time series data using Python.', 'python'),\n",
    "(67, 'Forecasting Using ARIMA Models in Python', 'Have you ever tried to predict the future? What lies ahead is a mystery which is usually only solved by waiting. In this course, you will stop waiting and learn to use the powerful ARIMA class models to forecast the future. You will learn how to use the statsmodels package to analyze time series, to build tailored models, and to forecast under uncertainty. How will the stock market move in the next 24 hours? How will the levels of CO2 change in the next decade? How many earthquakes will there be next year? You will learn to solve all these problems and more.', 'python'),\n",
    "(68, 'Analyzing Business Data in SQL', 'Businesses nowadays track data on everything, from operations to marketing to HR. Leveraging this data enables businesses to understand themselves and their customers, leading to higher profits and better performance. In this course, youâ€™ll learn about the key metrics that businesses use to measure performance. You''ll write SQL queries to calculate these metrics and produce report-ready results. Throughout the course, you''ll study the data of Delivr, a fictional food delivery startup; this data is modeled on real companies'' datasets.', 'sql'),\n",
    "(69, 'Statistical Simulation in Python', 'Simulations are a class of computational algorithms that use the relatively simple idea of random sampling to solve increasingly complex problems. Although they have been around for ages, they have gained in popularity recently due to the rise in computational power and have seen applications in multiple domains including Artificial Intelligence, Physics, Computational Biology and Finance just to name a few. Students will use simulations to generate and analyze data over different probability distributions using the important NumPy package. This course will give students hands-on experience with simulations using simple, real-world applications.', 'python'),\n",
    "(70, 'Introduction to Relational Databases in SQL', 'You have already used SQL for querying data from databases. But did you actually know that there''s a whole lot more you can do with databases? You can model different phenomena in your data â€“ and relationships between them. This gives your data structure as well as consistency, which results in better data quality. In this course, you''ll experience this firsthand by working with a real-life data set that was used to investigate questionable affiliations of universities. Column by column, table by table, you''ll get to unlock and admire the full potential of databases. In between, you''ll learn how to create tables and specify their relationships as well as how to enforce data integrity. Also, you''ll discover other unique features of database systems, such as constraints.', 'sql'),\n",
    "(71, 'Differential Expression Analysis in R with limma', 'Functional genomic technologies like microarrays, sequencing, and mass spectrometry enable scientists to gather unbiased measurements of gene expression levels on a genome-wide scale. Whether you are generating your own data or want to explore the large number of publicly available data sets, you will first need to learn how to analyze these types of experiments. In this course, you will be taught how to use the versatile R/Bioconductor package limma to perform a differential expression analysis on the most common experimental designs. Furthermore, you will learn how to pre-process the data, identify and correct for batch effects, visually assess the results, and perform enrichment testing. After completing this course, you will have general analysis strategies for gaining insight from any functional genomics study.', 'r'),\n",
    "(72, 'Natural Language Processing Fundamentals in Python', 'In this course, you''ll learn Natural Language Processing (NLP) basics, such as how to identify and separate words, how to extract topics in a text, and how to build your own fake news classifier. You''ll also learn how to use basic libraries such as NLTK, alongside libraries which utilize deep learning to solve common NLP problems. This course will give you the foundation to process and parse text as you move forward in your Python learning.', 'python'),\n",
    "(73, 'Financial Trading in R', 'This course will cover the basics on financial trading and will give you an overview of how to use quantstrat to build signal-based trading strategies in R. It will teach you how to set up a quantstrat strategy, apply transformations of market data called indicators, create signals based on the interactions of those indicators, and even simulate orders. Lastly, it will explain how to analyze your results both from statistical and visual perspectives.', NULL),\n",
    "(74, 'Valuation of Life Insurance Products in R', 'Understanding the basic principles of life insurance products is essential for your personal financial planning, ranging from taking out a mortgage to designing your retirement plan and seeking financial protection for the risk of dying early. In this course, you''ll study the time value of money and youâ€™ll work with human mortality data to derive demographic markers (such as the life expectancy). Combining the basics of cash flow valuation with the calculation of survival and death probabilities in R will allow you to construct insightful tools to design life insurance products. You''ll come out of this course understanding the valuation of life contingent claims: life annuities, which provide an income upon survival, and life insurance products, which pay a benefit upon death of the policyholder.', 'r'),\n",
    "(75, 'Data Visualization with Seaborn', 'Do you want to make beautiful, informative visualizations with ease? If so, then you must learn seaborn! Seaborn is a visualization library that is an essential part of the python data science toolkit. In this course, you will learn how to use seaborn''s sophisticated visualization tools to analyze multiple real world datasets including the American Housing Survey, college tuition data, and guests from the popular television series, The Daily Show. Following this course, you will be able to use seaborn functions to visualize your data in several different formats and customize seaborn plots for your unique needs.', 'python'),\n",
    "(76, 'Interactive Maps with leaflet in R', 'Get ready to have some fun with maps! Interactive Maps with leaflet in R will give you the tools to make attractive and interactive web maps using spatial data and the tidyverse. In this course, you will create maps using the IPEDS dataset, which contains data on U.S. colleges and universities. Along the way, you will customize our maps using labels, popups, and custom markers, and add layers to enhance interactivity. Following the course, you will be able to create and customize your own interactive web maps to reveal patterns in your data.', 'r'),\n",
    "(77, 'Intro to Statistics with R: Moderation and Mediation', 'Moderation and mediation sound alike, but in reality they are quite different. This course will get you acquainted with these complex analytical techniques based on multiple regression. Special attention will go to centering predictors as a way to improve interpretability of results.', NULL),\n",
    "(78, 'Network Analysis in Python (Part 2)', 'Have you taken DataCamp''s Network Analysis in Python (Part 1) course and are yearning to learn more sophisticated techniques to analyze your networks, whether they be social, transportation, or biological? Then this is the course for you! Herein, you''ll build on your knowledge and skills to tackle more advanced problems in network analytics! You''ll gain the conceptual and practical skills to analyze evolving time series of networks, learn about bipartite graphs, and how to use bipartite graphs in product recommendation systems. You''ll also learn about graph projections, why they''re so useful in Data Science, and figure out the best ways to store and load graph data from files. You''ll consolidate all of this knowledge in a final chapter case study, in which you''ll analyze a forum dataset and come out of this course a Pythonista Network Analyst ninja!', 'python'),\n",
    "(79, 'Developing R Packages', 'In this course, you will learn the end-to-end process for creating an R package from scratch. You will start off by creating the basic structure for your package, and adding in important details like functions and metadata. Once the basic components of your package are in place, you will learn about how to document your package, and why this is important for creating quality packages that other people - as well as your future self - can use with ease. Once you have created the components of your package, you will learn how to test they work properly, by creating tests, running checks, and building your package. By the end of this course you can expect to have all the necessary skills to create and share your own R packages.', 'r'),\n",
    "(80, 'String Manipulation in R with stringr', 'Character strings can turn up in all stages of a data science project. You might have to clean messy string input before analysis, extract data that is embedded in text or automatically turn numeric results into a sentence to include in a report. Perhaps the strings themselves are the data of interest, and you need to detect and match patterns within them. This course will help you master these tasks by teaching you how to pull strings apart, put them back together and use stringr to detect, extract, match and split strings using regular expressions, a powerful way to express patterns.', 'r'),\n",
    "(81, 'Exploratory Data Analysis in R: Case Study', 'Once you''ve started learning tools for data manipulation and visualization like dplyr and ggplot2, this course gives you a chance to use them in action on a real dataset. You''ll explore the historical voting of the United Nations General Assembly, including analyzing differences in voting between countries, across time, and among international issues. In the process you''ll gain more practice with the dplyr and ggplot2 packages, learn about the broom package for tidying model output, and experience the kind of start-to-finish exploratory analysis common in data science.', 'r'),\n",
    "(82, 'Conda for Building & Distributing Packages', 'Now that you''re proficient in many areas of data science with Python it''s time to share your code and data with others. In this course you''ll learn the fundamentals of sharing your data science assets. You''ll learn how to leverage Anaconda Projects to package data, code, and conda environments into a single archive for other data scientists to run. You''ll learn the basics of creating Python packages that provide importable modules. Finally, you''ll learn how to write Conda recipes for your packages, build them, and share them on Anaconda Cloud.', 'shell'),\n",
    "(83, 'Course Creation at DataCamp', 'Welcome to the DataCamp family! You are about to begin creating a course that, in just a few months, will be available to over 3 million students worldwide! If you''re new to eLearning, you''ll soon learn that teaching an online course is very different from teaching in a classroom. But we''re here to help! This course will provide a guide to the DataCamp Course Creation process; an introduction to the tools we use, including GitHub, Asana, and our very own course editor; and the different types of exercises and slides you can use, and how to make sure you''re reaching students at the other end of the screen. While creating your course, you will find you have other questions, such as, \"How will my course be marketed?\", \"How do I recommend other instructors to DataCamp?\", or \"When do I get paid?\". This course will also provide you with direction on where to find answers to all your questions. Following this course, you should be familiar with the DataCamp Course Creation process and be ready to start your very own DataCamp course. Have fun and see you in the course!', 'r'),\n",
    "(84, 'Supervised Learning in R: Regression', 'From a machine learning perspective, regression is the task of predicting numerical outcomes from various inputs. In this course, you''ll learn about different regression models, how to train these models in R, how to evaluate the models you train and use them to make predictions.', 'r'),\n",
    "(85, 'Bond Valuation and Analysis in R', '<p>After this course on quantitative finance with R, you will be able to use R to develop a model to value a fixed interest rate bond, estimate and analyze a bond''s yield (i.e., a measure of the opportunity cost of bond investors), and model techniques used to protect bond portfolios from changes in interest rates.</p> <p><strong>Why value bonds?</strong><br>Bonds are securities issued by governments or corporations that pay interest over a fixed schedule and are the most well-known type of fixed income securities. The US fixed income market is 1.5x larger than the US stock market, but, unlike stocks, most fixed income instruments, including bonds, trade very infrequently. Consequently, a bond''s price may be a less reliable indicator of its value and analytical techniques are necessary when analyzing and valuing bonds.</p>', 'r'),\n",
    "(86, 'Building Recommendation Engines with PySpark', 'This course will show you how to build recommendation engines using Alternating Least Squares in PySpark. Using the popular MovieLens dataset and the Million Songs dataset, this course will take you step by step through the intuition of the Alternating Least Squares algorithm as well as the code to train, test and implement ALS models on various types of customer data. ', 'python'),\n",
    "(87, 'Introduction to Spark in R using sparklyr', 'R is mostly optimized to help you write data analysis code quickly and readably. Apache Spark is designed to analyze huge datasets quickly. The <code>sparklyr</code> package lets you write <code>dplyr</code> R code that runs on a Spark cluster, giving you the best of both worlds. This course teaches you how to manipulate Spark DataFrames using both the <code>dplyr</code> interface and the native interface to Spark, as well as trying machine learning techniques. Throughout the course, you''ll explore the Million Song Dataset.', 'r'),\n",
    "(88, 'Python for R Users', 'Python and R have seen immense growth in popularity in the \"Machine Learning Age\". They both are high-level languages that are easy to learn and write. The language you use will depend on your background and field of study and work. R is a language made by and for statisticians, whereas Python is a more general purpose programming language. Regardless of the background, there will be times when a particular algorithm is implemented in one language and not the other, a feature is better documented, or simply, the tutorial you found online uses Python instead of R.\n",
    "\n",
    "\n",
    "In either case, this would require the R user to work in Python to get his/her work done, or try to understand how something is implemented in Python for it to be translated into R. This course helps you cross the R-Python language barrier.', 'python'),\n",
    "(89, 'RNA-Seq Differential Expression Analysis', 'RNA-Seq is an exciting next-generation sequencing method used for identifying genes and pathways underlying particular diseases or conditions. As high-throughput sequencing becomes more affordable and accessible to a wider community of researchers, the knowledge to analyze this data is becoming an increasingly valuable skill. Join us in learning about the RNA-Seq workflow and discovering how to identify which genes and biological processes may be important for your condition of interest! We will start the course with a brief overview of the RNA-Seq workflow with an emphasis on differential expression (DE) analysis. Starting with the counts for each gene, the course will cover how to prepare data for DE analysis, assess the quality of the count data, and identify outliers and detect major sources of variation in the data. The DESeq2 R package will be used to model the count data using a negative binomial model and test for differentially expressed genes. Visualization of the results with heatmaps and volcano plots will be performed and the significant differentially expressed genes will be identified and saved.', 'r'),\n",
    "(90, 'pandas Foundations', 'Pandas DataFrames are the most widely used in-memory representation of complex data collections within Python. Whether in finance, scientific fields, or data science, a familiarity with Pandas is essential. This course teaches you to work with real-world data sets containing both string and numeric data, often structured around time series. You will learn powerful analysis, selection, and visualization techniques in this course.', 'python'),\n",
    "(92, 'Foundations of Predictive Analytics in Python (Part 2)', 'Building good models only succeeds if you have a decent base table to start with. In this course you will learn how to construct a good base table, create variables and prepare your data for modeling. We finish with advanced topics on the matter. If you have not already, you should take <a href=\"https://www.datacamp.com/courses/foundations-of-predictive-analytics-in-python-part-1\" target=\"_blank\">Foundations of Predictive Analytics in Python (Part 1)</a> first.', 'python'),\n",
    "(93, 'Python for MATLAB Users', 'Python is a versatile programming language that is becoming more and more popular for doing data science. Companies worldwide are using Python to harvest insights from their data and get a competitive edge. This course focuses on helping Matlab users learn to use Python specifically for data science. You will quickly learn how to migrate from Matlab to Python for data analysis and visualization. Learn the fundamentals of Python syntax, how to use numpy arrays to store and manipulate data. You will learn how to use matplotlib to discover trends, correlations, and patterns in real datasets, including bicycle traffic in the city of Seattle and avocado prices across the United States.', 'python'),\n",
    "(94, 'Sentiment Analysis in R: The Tidy Way', 'Text datasets are diverse and ubiquitous, and sentiment analysis provides an approach to understand the attitudes and opinions expressed in these texts. In this course, you will develop your text mining skills using tidy data principles. You will apply these skills by performing sentiment analysis in several case studies, on text data from Twitter to TV news to Shakespeare. These case studies will allow you to practice important data handling skills, learn about the ways sentiment analysis can be applied, and extract relevant insights from real-world data.', 'r'),\n",
    "(95, 'Python Data Science Toolbox (Part 2)', 'In this second course in the Python Data Science Toolbox, you''ll continue to build your Python Data Science skills. First you''ll enter the wonderful world of iterators, objects that you have already encountered in the context of for loops without having necessarily known it. You''ll then learn about list comprehensions, which are extremely handy tools that form a basic component in the toolbox of all modern Data Scientists working in Python. You''ll end the course by working through a case study in which you''ll apply all of the techniques you learned both in this course as well as the prequel. If you''re looking to make it as a Pythonista Data Science ninja, you have come to the right place.', 'python'),\n",
    "(96, 'Intro to SQL for Data Science', 'The role of a data scientist is to turn raw data into actionable insights. Much of the world''s raw data&ndash;from electronic medical records to customer transaction histories&ndash;lives in organized collections of tables called <em>relational databases</em>. Therefore, to be an effective data scientist, you must know how to wrangle and extract data from these databases using a language called SQL (pronounced <em>ess-cue-ell</em>, or <em>sequel</em>). This course teaches syntax in SQL shared by many types of databases, such as PostgreSQL, MySQL, SQL Server, and Oracle.This course teaches you everything you need to know to begin working with databases today!', 'sql'),\n",
    "(97, 'Foundations of Predictive Analytics in Python (Part 1)', 'In this course, you will learn how to build a logistic regression model with meaningful variables. You will also learn how to use this model to make predictions and how to present it and its performance to business stakeholders.', 'python'),\n",
    "(98, 'Building Chatbots in Python', 'When done well, interacting with a computer through human language is incredibly powerful and also quite fun. Messaging and Voice-Controlled devices are the next big platforms, and conversational computing has a big role to play in creating engaging augmented and virtual reality experiences. This course will get you started on the path towards building such applications! There are a number of unique challenges to building these kinds of programs. The most obvious one is of course - how do I turn human language into machine instructions? In this course, you''ll tackle this first with rule-based systems and then with machine learning. Some chat systems are designed to be useful, while others are just good fun. You will build one of each, and finally put everything together to make a helpful, friendly chatbot! And once you complete the course, you can learn how to <a href=\"https://www.datacamp.com/community/tutorials/facebook-chatbot-python-deploy\" target=\"_blank\">connect your chatbot to Facebook Messenger!</a>', 'python'),\n",
    "(99, 'Predictive Analytics using Networked Data in R', 'In this course, you will learn to perform state-of-the art predictive analytics using networked data in R. The aim of network analytics is to predict to which class a network node belongs, such as churner or not, fraudster or not, defaulter or not, etc. To accomplish this, we discuss how to leverage information from the network and its underlying structure in a predictive way. More specifically, we introduce the idea of featurization such that network features can be added to non-network features as such boosting the performance of any resulting analytical model. In this course, you will use the igraph package to generate and label a network of customers in a churn setting and learn about the foundations of network learning. Then, you will learn about homophily, dyadicity and heterophilicty, and how these can be used to get key exploratory insights in your network. Next, you will use the functionality of the igraph package to compute various network features to calculate both node-centric as well as neighbor based network features. Furthermore, you will use the Google PageRank algorithm to compute network features and empirically validate their predictive power. Finally, we teach you how to generate a flat dataset from the network and analyze it using logistic regression and random forests.', 'r'),\n",
    "(100, 'Working with Dates and Times in Python', 'You''ll probably never have a time machine, but how about a machine for analyzing time? As soon as time enters any analysis, things can get weird. It''s easy to get tripped up on day and month boundaries, time zones, daylight saving time, and all sorts of other things that can confuse the unprepared. If you''re going to do any kind of analysis involving time, youâ€™ll want to use Python to sort it out. Working with data sets on hurricanes and bike trips, weâ€™ll cover counting events, figuring out how much time has elapsed between events and plotting data over time. You''ll work in both standard Python and in Pandas, and we''ll touch on the dateutil library, the only timezone library endorsed by the official Python documentation. After this course, you''ll confidently handle date and time data in any format like a champion.', 'python')\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query executed sucessfully\n"
     ]
    }
   ],
   "source": [
    "execute_query(connection,insert_course)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_ratings = \"\"\"\n",
    "INSERT INTO\n",
    "ratings (user_id,course_id,rating)\n",
    "VALUES\n",
    "('1', '6', '4'),\n",
    "('1', '36', '5'),\n",
    "('1', '37', '5'),\n",
    "('1', '45', '5'),\n",
    "('1', '50', '5'),\n",
    "('1', '81', '5'),\n",
    "('2', '50', '4'),\n",
    "('2', '81', '4'),\n",
    "('3', '11', '5'),\n",
    "('3', '16', '4'),\n",
    "('3', '31', '5'),\n",
    "('3', '35', '5'),\n",
    "('3', '37', '5'),\n",
    "('3', '38', '5'),\n",
    "('3', '47', '5'),\n",
    "('3', '49', '4'),\n",
    "('3', '53', '5'),\n",
    "('3', '55', '5'),\n",
    "('3', '57', '5'),\n",
    "('3', '58', '5'),\n",
    "('3', '65', '5'),\n",
    "('3', '76', '5'),\n",
    "('3', '84', '5'),\n",
    "('3', '87', '5'),\n",
    "('3', '99', '5'),\n",
    "('4', '96', '5'),\n",
    "('5', '3', '4'),\n",
    "('5', '9', '3'),\n",
    "('5', '31', '4'),\n",
    "('5', '96', '4'),\n",
    "('6', '70', '5'),\n",
    "('6', '96', '4'),\n",
    "('7', '96', '4'),\n",
    "('8', '25', '5'),\n",
    "('8', '96', '5'),\n",
    "('9', '7', '4'),\n",
    "('9', '18', '4'),\n",
    "('9', '32', '4'),\n",
    "('9', '36', '4'),\n",
    "('9', '70', '4'),\n",
    "('9', '90', '4'),\n",
    "('9', '95', '4'),\n",
    "('9', '96', '4'),\n",
    "('10', '36', '5'),\n",
    "('10', '90', '4'),\n",
    "('11', '6', '4'),\n",
    "('11', '32', '5'),\n",
    "('11', '44', '5'),\n",
    "('11', '96', '4'),\n",
    "('12', '44', '4'),\n",
    "('13', '6', '5'),\n",
    "('13', '18', '5'),\n",
    "('13', '26', '5'),\n",
    "('13', '33', '5'),\n",
    "('13', '44', '5'),\n",
    "('13', '59', '5'),\n",
    "('13', '70', '5'),\n",
    "('13', '78', '5'),\n",
    "('13', '96', '5'),\n",
    "('14', '6', '4'),\n",
    "('14', '70', '5'),\n",
    "('14', '91', '5'),\n",
    "('15', '6', '5'),\n",
    "('15', '96', '3'),\n",
    "('16', '42', '3'),\n",
    "('17', '3', '5'),\n",
    "('17', '64', '5'),\n",
    "('17', '91', '5'),\n",
    "('17', '96', '5'),\n",
    "('18', '91', '5'),\n",
    "('18', '96', '5'),\n",
    "('19', '7', '3'),\n",
    "('19', '32', '4'),\n",
    "('19', '36', '5'),\n",
    "('19', '90', '4'),\n",
    "('19', '95', '4'),\n",
    "('20', '90', '4'),\n",
    "('21', '68', '5'),\n",
    "('22', '52', '5'),\n",
    "('23', '7', '4'),\n",
    "('23', '32', '4'),\n",
    "('24', '7', '3'),\n",
    "('24', '18', '2'),\n",
    "('24', '32', '4'),\n",
    "('25', '32', '5'),\n",
    "('26', '7', '5'),\n",
    "('26', '32', '5'),\n",
    "('26', '95', '5'),\n",
    "('27', '7', '5'),\n",
    "('27', '32', '5'),\n",
    "('27', '36', '3'),\n",
    "('27', '70', '5'),\n",
    "('27', '90', '3'),\n",
    "('27', '95', '3'),\n",
    "('27', '96', '5'),\n",
    "('28', '7', '5'),\n",
    "('28', '32', '5'),\n",
    "('29', '7', '4'),\n",
    "('29', '32', '3'),\n",
    "('30', '6', '5'),\n",
    "('30', '96', '5'),\n",
    "('31', '6', '3'),\n",
    "('32', '7', '5'),\n",
    "('32', '33', '5'),\n",
    "('32', '90', '4'),\n",
    "('33', '60', '4'),\n",
    "('33', '95', '4'),\n",
    "('34', '18', '5'),\n",
    "('35', '3', '5'),\n",
    "('35', '6', '5'),\n",
    "('35', '18', '5'),\n",
    "('35', '20', '5'),\n",
    "('35', '42', '5'),\n",
    "('35', '45', '5'),\n",
    "('35', '50', '5'),\n",
    "('35', '64', '5'),\n",
    "('35', '81', '5'),\n",
    "('35', '90', '5'),\n",
    "('35', '91', '5'),\n",
    "('36', '96', '5'),\n",
    "('37', '44', '5'),\n",
    "('38', '32', '5'),\n",
    "('39', '32', '5'),\n",
    "('39', '36', '5'),\n",
    "('39', '95', '5'),\n",
    "('40', '7', '5'),\n",
    "('40', '32', '4'),\n",
    "('40', '36', '4'),\n",
    "('40', '95', '4'),\n",
    "('41', '90', '4'),\n",
    "('41', '95', '4'),\n",
    "('42', '64', '5'),\n",
    "('42', '91', '4'),\n",
    "('43', '3', '5'),\n",
    "('43', '64', '5'),\n",
    "('44', '64', '5'),\n",
    "('44', '91', '5'),\n",
    "('45', '43', '3'),\n",
    "('45', '64', '5'),\n",
    "('45', '96', '4'),\n",
    "('46', '7', '5'),\n",
    "('46', '32', '5'),\n",
    "('46', '95', '4'),\n",
    "('47', '32', '5'),\n",
    "('48', '7', '5'),\n",
    "('48', '32', '5'),\n",
    "('49', '7', '3'),\n",
    "('49', '32', '3'),\n",
    "('50', '3', '4'),\n",
    "('51', '3', '3'),\n",
    "('51', '51', '4'),\n",
    "('52', '3', '5'),\n",
    "('52', '6', '5'),\n",
    "('52', '64', '5'),\n",
    "('52', '70', '5'),\n",
    "('52', '91', '5'),\n",
    "('52', '96', '5'),\n",
    "('53', '7', '5'),\n",
    "('53', '64', '4'),\n",
    "('53', '91', '5'),\n",
    "('54', '7', '4'),\n",
    "('54', '96', '5'),\n",
    "('55', '96', '4'),\n",
    "('56', '7', '3'),\n",
    "('56', '96', '5'),\n",
    "('57', '96', '5'),\n",
    "('58', '96', '5'),\n",
    "('59', '96', '5'),\n",
    "('60', '4', '3'),\n",
    "('60', '6', '4'),\n",
    "('60', '7', '4'),\n",
    "('60', '22', '4'),\n",
    "('60', '29', '4'),\n",
    "('60', '32', '4'),\n",
    "('60', '37', '4'),\n",
    "('60', '58', '4'),\n",
    "('60', '70', '4'),\n",
    "('60', '76', '4'),\n",
    "('60', '80', '4'),\n",
    "('60', '81', '4'),\n",
    "('60', '96', '5'),\n",
    "('60', '99', '4'),\n",
    "('61', '3', '5'),\n",
    "('61', '42', '4'),\n",
    "('61', '43', '5'),\n",
    "('61', '70', '5'),\n",
    "('62', '70', '5'),\n",
    "('62', '96', '5'),\n",
    "('63', '32', '3'),\n",
    "('63', '36', '4'),\n",
    "('63', '70', '4'),\n",
    "('63', '90', '4'),\n",
    "('63', '95', '4'),\n",
    "('63', '96', '5'),\n",
    "('64', '18', '4'),\n",
    "('65', '7', '3'),\n",
    "('65', '80', '3'),\n",
    "('66', '7', '4'),\n",
    "('67', '7', '5'),\n",
    "('68', '7', '5'),\n",
    "('69', '7', '5'),\n",
    "('69', '44', '5'),\n",
    "('70', '7', '4'),\n",
    "('71', '7', '5'),\n",
    "('72', '7', '5'),\n",
    "('73', '7', '5'),\n",
    "('74', '7', '5'),\n",
    "('75', '7', '5'),\n",
    "('76', '7', '5'),\n",
    "('76', '32', '5'),\n",
    "('77', '7', '5'),\n",
    "('78', '7', '5'),\n",
    "('79', '3', '5'),\n",
    "('79', '4', '3'),\n",
    "('80', '3', '4'),\n",
    "('81', '3', '5'),\n",
    "('82', '20', '5'),\n",
    "('83', '7', '2'),\n",
    "('84', '7', '4'),\n",
    "('84', '32', '4'),\n",
    "('85', '3', '5'),\n",
    "('85', '6', '5'),\n",
    "('85', '7', '5'),\n",
    "('85', '32', '5'),\n",
    "('85', '52', '3'),\n",
    "('85', '64', '5'),\n",
    "('85', '70', '5'),\n",
    "('85', '91', '5'),\n",
    "('85', '96', '5'),\n",
    "('86', '3', '4'),\n",
    "('87', '3', '5'),\n",
    "('87', '64', '5'),\n",
    "('88', '7', '5'),\n",
    "('89', '7', '5'),\n",
    "('89', '26', '5'),\n",
    "('89', '33', '5'),\n",
    "('90', '96', '5'),\n",
    "('91', '96', '5'),\n",
    "('92', '96', '5'),\n",
    "('93', '96', '5'),\n",
    "('94', '6', '3'),\n",
    "('94', '32', '4'),\n",
    "('94', '36', '4'),\n",
    "('94', '44', '5'),\n",
    "('94', '70', '5'),\n",
    "('94', '90', '4'),\n",
    "('94', '96', '5'),\n",
    "('95', '6', '4'),\n",
    "('95', '96', '4'),\n",
    "('96', '62', '5'),\n",
    "('96', '65', '5'),\n",
    "('96', '73', '5'),\n",
    "('96', '85', '5'),\n",
    "('97', '15', '4'),\n",
    "('97', '21', '2'),\n",
    "('97', '68', '3'),\n",
    "('98', '7', '5'),\n",
    "('98', '32', '5'),\n",
    "('98', '36', '5'),\n",
    "('98', '95', '5'),\n",
    "('99', '19', '5'),\n",
    "('99', '36', '5'),\n",
    "('100', '36', '5'),\n",
    "('100', '95', '5'),\n",
    "('101', '32', '5'),\n",
    "('101', '36', '5'),\n",
    "('101', '95', '5'),\n",
    "('102', '44', '5'),\n",
    "('103', '32', '5'),\n",
    "('104', '6', '5'),\n",
    "('104', '7', '5'),\n",
    "('104', '18', '4'),\n",
    "('104', '32', '5'),\n",
    "('104', '36', '5'),\n",
    "('104', '42', '5'),\n",
    "('104', '44', '5'),\n",
    "('104', '70', '5'),\n",
    "('104', '90', '5'),\n",
    "('104', '95', '5'),\n",
    "('104', '96', '5'),\n",
    "('105', '7', '5'),\n",
    "('105', '32', '5'),\n",
    "('105', '95', '5'),\n",
    "('106', '7', '5'),\n",
    "('106', '20', '5'),\n",
    "('106', '32', '5'),\n",
    "('106', '36', '5'),\n",
    "('106', '90', '5'),\n",
    "('106', '95', '5'),\n",
    "('106', '96', '5'),\n",
    "('107', '32', '4'),\n",
    "('108', '7', '5'),\n",
    "('108', '32', '5'),\n",
    "('109', '6', '4'),\n",
    "('109', '18', '4'),\n",
    "('109', '42', '4'),\n",
    "('109', '70', '4'),\n",
    "('109', '96', '4'),\n",
    "('110', '18', '2'),\n",
    "('111', '6', '5'),\n",
    "('111', '18', '5'),\n",
    "('111', '20', '5'),\n",
    "('111', '31', '5'),\n",
    "('111', '42', '2'),\n",
    "('111', '70', '5'),\n",
    "('111', '72', '5'),\n",
    "('111', '78', '5'),\n",
    "('111', '98', '4'),\n",
    "('112', '97', '5'),\n",
    "('113', '60', '5'),\n",
    "('114', '6', '5'),\n",
    "('114', '70', '5'),\n",
    "('114', '91', '5'),\n",
    "('114', '96', '5'),\n",
    "('115', '6', '4'),\n",
    "('116', '6', '5'),\n",
    "('116', '42', '5'),\n",
    "('117', '6', '3'),\n",
    "('117', '96', '4'),\n",
    "('118', '20', '5'),\n",
    "('119', '14', '5'),\n",
    "('120', '6', '4'),\n",
    "('120', '70', '4'),\n",
    "('120', '91', '5'),\n",
    "('120', '96', '5'),\n",
    "('121', '90', '5'),\n",
    "('122', '20', '4'),\n",
    "('122', '32', '5'),\n",
    "('122', '90', '5'),\n",
    "('122', '95', '5'),\n",
    "('123', '6', '5'),\n",
    "('123', '68', '5'),\n",
    "('124', '57', '3'),\n",
    "('125', '50', '5'),\n",
    "('126', '95', '5'),\n",
    "('127', '16', '5'),\n",
    "('127', '65', '5'),\n",
    "('128', '75', '5'),\n",
    "('129', '7', '4'),\n",
    "('129', '32', '5'),\n",
    "('130', '88', '4'),\n",
    "('131', '6', '4'),\n",
    "('131', '18', '5'),\n",
    "('131', '42', '5'),\n",
    "('131', '70', '5'),\n",
    "('132', '6', '5'),\n",
    "('133', '6', '5'),\n",
    "('134', '33', '4'),\n",
    "('135', '32', '4'),\n",
    "('135', '33', '4'),\n",
    "('135', '44', '4'),\n",
    "('136', '26', '5'),\n",
    "('137', '3', '5'),\n",
    "('137', '4', '5'),\n",
    "('137', '64', '5'),\n",
    "('138', '3', '4'),\n",
    "('138', '4', '4'),\n",
    "('139', '3', '5'),\n",
    "('139', '6', '5'),\n",
    "('139', '20', '5'),\n",
    "('139', '64', '5'),\n",
    "('139', '70', '5'),\n",
    "('139', '91', '5'),\n",
    "('139', '96', '5'),\n",
    "('140', '96', '5'),\n",
    "('141', '96', '5'),\n",
    "('142', '81', '5'),\n",
    "('143', '96', '3'),\n",
    "('144', '7', '5'),\n",
    "('144', '32', '5'),\n",
    "('144', '36', '5'),\n",
    "('144', '70', '5'),\n",
    "('144', '90', '5'),\n",
    "('144', '95', '5'),\n",
    "('144', '96', '5'),\n",
    "('145', '70', '5'),\n",
    "('146', '64', '4'),\n",
    "('146', '91', '5'),\n",
    "('147', '7', '5'),\n",
    "('148', '7', '5'),\n",
    "('148', '42', '5'),\n",
    "('149', '7', '2'),\n",
    "('150', '7', '4'),\n",
    "('151', '7', '5'),\n",
    "('152', '7', '4'),\n",
    "('153', '7', '5'),\n",
    "('154', '7', '5'),\n",
    "('155', '7', '5'),\n",
    "('156', '7', '5'),\n",
    "('157', '7', '5'),\n",
    "('158', '7', '5'),\n",
    "('159', '7', '4'),\n",
    "('160', '7', '5'),\n",
    "('161', '7', '5'),\n",
    "('162', '7', '5'),\n",
    "('163', '7', '5'),\n",
    "('164', '7', '4'),\n",
    "('164', '32', '4'),\n",
    "('165', '7', '5'),\n",
    "('166', '7', '5'),\n",
    "('167', '7', '5'),\n",
    "('168', '3', '5'),\n",
    "('169', '32', '5'),\n",
    "('170', '28', '5'),\n",
    "('170', '32', '4'),\n",
    "('171', '7', '3'),\n",
    "('171', '32', '4'),\n",
    "('171', '44', '4'),\n",
    "('172', '7', '5'),\n",
    "('173', '7', '5'),\n",
    "('173', '32', '5'),\n",
    "('174', '7', '5'),\n",
    "('175', '7', '5'),\n",
    "('176', '7', '4'),\n",
    "('176', '88', '4'),\n",
    "('177', '7', '5'),\n",
    "('177', '32', '4'),\n",
    "('177', '36', '5'),\n",
    "('177', '70', '2'),\n",
    "('177', '90', '4'),\n",
    "('177', '95', '4'),\n",
    "('177', '96', '3'),\n",
    "('178', '52', '5'),\n",
    "('179', '3', '5'),\n",
    "('179', '64', '5'),\n",
    "('179', '91', '5'),\n",
    "('180', '4', '5'),\n",
    "('181', '7', '5'),\n",
    "('182', '42', '1'),\n",
    "('183', '33', '5'),\n",
    "('184', '96', '4'),\n",
    "('185', '6', '5'),\n",
    "('185', '64', '5'),\n",
    "('185', '91', '5'),\n",
    "('185', '96', '5'),\n",
    "('186', '96', '5'),\n",
    "('187', '7', '5'),\n",
    "('187', '96', '5'),\n",
    "('188', '70', '5'),\n",
    "('188', '90', '2'),\n",
    "('188', '96', '4'),\n",
    "('189', '96', '5'),\n",
    "('190', '53', '5'),\n",
    "('191', '45', '5'),\n",
    "('192', '11', '5'),\n",
    "('192', '25', '5'),\n",
    "('192', '45', '5'),\n",
    "('192', '58', '5'),\n",
    "('193', '42', '5'),\n",
    "('193', '90', '5'),\n",
    "('194', '15', '5'),\n",
    "('195', '6', '4'),\n",
    "('196', '6', '5'),\n",
    "('196', '42', '5'),\n",
    "('196', '44', '5'),\n",
    "('196', '70', '5'),\n",
    "('197', '6', '5'),\n",
    "('197', '18', '5'),\n",
    "('198', '3', '5'),\n",
    "('198', '64', '4'),\n",
    "('199', '3', '5'),\n",
    "('199', '6', '5'),\n",
    "('199', '48', '5'),\n",
    "('199', '64', '5'),\n",
    "('199', '81', '5'),\n",
    "('199', '91', '5'),\n",
    "('199', '96', '5'),\n",
    "('200', '64', '5'),\n",
    "('201', '6', '4'),\n",
    "('201', '64', '5'),\n",
    "('201', '70', '5'),\n",
    "('201', '91', '5'),\n",
    "('201', '96', '5'),\n",
    "('202', '7', '5'),\n",
    "('202', '32', '5'),\n",
    "('202', '36', '4'),\n",
    "('202', '90', '5'),\n",
    "('202', '95', '4'),\n",
    "('203', '7', '5'),\n",
    "('203', '32', '5'),\n",
    "('203', '95', '5'),\n",
    "('204', '7', '5'),\n",
    "('204', '32', '5'),\n",
    "('204', '36', '5'),\n",
    "('204', '95', '5'),\n",
    "('205', '90', '5'),\n",
    "('206', '7', '5'),\n",
    "('206', '32', '5'),\n",
    "('206', '36', '5'),\n",
    "('206', '90', '5'),\n",
    "('206', '95', '5'),\n",
    "('207', '72', '5'),\n",
    "('208', '48', '4'),\n",
    "('208', '81', '4'),\n",
    "('209', '15', '3'),\n",
    "('209', '96', '5'),\n",
    "('210', '6', '5'),\n",
    "('210', '18', '5'),\n",
    "('210', '20', '5'),\n",
    "('210', '42', '5'),\n",
    "('210', '70', '5'),\n",
    "('210', '96', '5'),\n",
    "('211', '6', '5'),\n",
    "('211', '96', '5'),\n",
    "('212', '97', '4'),\n",
    "('213', '32', '5'),\n",
    "('214', '7', '3'),\n",
    "('214', '32', '4'),\n",
    "('214', '90', '5'),\n",
    "('214', '96', '4'),\n",
    "('215', '32', '5'),\n",
    "('216', '32', '4'),\n",
    "('217', '32', '5'),\n",
    "('218', '32', '4'),\n",
    "('218', '36', '4'),\n",
    "('218', '95', '4'),\n",
    "('218', '96', '4'),\n",
    "('219', '7', '5'),\n",
    "('219', '32', '5'),\n",
    "('219', '36', '5'),\n",
    "('219', '95', '5'),\n",
    "('220', '7', '4'),\n",
    "('220', '32', '5'),\n",
    "('221', '7', '4'),\n",
    "('221', '32', '4'),\n",
    "('221', '95', '4'),\n",
    "('222', '32', '5'),\n",
    "('223', '7', '4'),\n",
    "('223', '32', '4'),\n",
    "('224', '18', '5'),\n",
    "('225', '7', '5'),\n",
    "('225', '60', '5'),\n",
    "('226', '7', '5'),\n",
    "('226', '32', '5'),\n",
    "('227', '32', '3'),\n",
    "('228', '7', '5'),\n",
    "('228', '32', '5'),\n",
    "('229', '3', '5'),\n",
    "('229', '50', '4'),\n",
    "('230', '7', '5'),\n",
    "('230', '45', '5'),\n",
    "('230', '50', '4'),\n",
    "('231', '6', '5'),\n",
    "('231', '96', '5'),\n",
    "('232', '6', '5'),\n",
    "('232', '96', '5'),\n",
    "('233', '3', '5'),\n",
    "('234', '3', '4'),\n",
    "('234', '65', '5'),\n",
    "('235', '32', '4'),\n",
    "('236', '6', '2'),\n",
    "('236', '96', '5'),\n",
    "('237', '88', '5'),\n",
    "('238', '33', '5'),\n",
    "('239', '70', '5'),\n",
    "('240', '70', '5'),\n",
    "('241', '70', '4'),\n",
    "('242', '6', '3'),\n",
    "('242', '70', '4'),\n",
    "('242', '96', '5'),\n",
    "('243', '20', '5'),\n",
    "('243', '50', '5'),\n",
    "('243', '70', '5'),\n",
    "('244', '14', '4'),\n",
    "('244', '31', '5'),\n",
    "('244', '42', '1'),\n",
    "('244', '70', '5'),\n",
    "('245', '7', '5'),\n",
    "('245', '32', '5'),\n",
    "('245', '96', '4'),\n",
    "('246', '96', '5'),\n",
    "('247', '7', '5'),\n",
    "('247', '96', '5'),\n",
    "('248', '96', '5'),\n",
    "('249', '7', '5'),\n",
    "('250', '7', '5'),\n",
    "('251', '7', '5'),\n",
    "('252', '7', '5'),\n",
    "('253', '7', '5'),\n",
    "('253', '32', '5'),\n",
    "('253', '43', '5'),\n",
    "('254', '7', '5'),\n",
    "('255', '7', '5'),\n",
    "('256', '7', '5'),\n",
    "('257', '7', '5'),\n",
    "('258', '7', '5'),\n",
    "('259', '7', '4'),\n",
    "('260', '7', '2'),\n",
    "('261', '7', '3'),\n",
    "('261', '32', '3'),\n",
    "('262', '7', '5'),\n",
    "('263', '7', '5'),\n",
    "('264', '7', '5'),\n",
    "('265', '7', '5'),\n",
    "('266', '7', '5'),\n",
    "('267', '7', '4'),\n",
    "('267', '32', '5'),\n",
    "('268', '7', '5'),\n",
    "('269', '7', '5'),\n",
    "('270', '7', '5'),\n",
    "('271', '7', '3'),\n",
    "('272', '7', '5'),\n",
    "('272', '32', '5'),\n",
    "('272', '58', '5'),\n",
    "('273', '32', '5'),\n",
    "('274', '6', '4'),\n",
    "('274', '31', '5'),\n",
    "('274', '70', '4'),\n",
    "('274', '81', '5'),\n",
    "('274', '96', '4'),\n",
    "('275', '31', '1'),\n",
    "('276', '3', '4'),\n",
    "('276', '48', '4'),\n",
    "('276', '96', '5'),\n",
    "('277', '7', '5'),\n",
    "('278', '7', '5'),\n",
    "('279', '45', '5'),\n",
    "('280', '96', '5'),\n",
    "('281', '95', '4'),\n",
    "('281', '96', '4'),\n",
    "('282', '6', '5'),\n",
    "('282', '70', '5'),\n",
    "('282', '96', '5'),\n",
    "('283', '36', '4'),\n",
    "('283', '70', '5'),\n",
    "('283', '90', '4'),\n",
    "('283', '95', '5'),\n",
    "('283', '96', '5'),\n",
    "('284', '6', '5'),\n",
    "('284', '96', '5'),\n",
    "('285', '32', '5'),\n",
    "('285', '36', '3'),\n",
    "('285', '95', '4'),\n",
    "('286', '9', '5'),\n",
    "('287', '6', '5'),\n",
    "('287', '18', '5'),\n",
    "('287', '42', '5'),\n",
    "('287', '70', '4'),\n",
    "('287', '90', '5'),\n",
    "('287', '96', '5'),\n",
    "('288', '6', '5'),\n",
    "('288', '18', '5'),\n",
    "('288', '42', '3'),\n",
    "('289', '1', '5'),\n",
    "('289', '42', '5'),\n",
    "('289', '44', '5'),\n",
    "('289', '70', '5'),\n",
    "('290', '42', '5'),\n",
    "('291', '6', '5'),\n",
    "('292', '6', '1'),\n",
    "('292', '36', '4'),\n",
    "('292', '44', '3'),\n",
    "('292', '96', '2'),\n",
    "('293', '6', '5'),\n",
    "('293', '36', '5'),\n",
    "('293', '90', '5'),\n",
    "('293', '96', '5'),\n",
    "('294', '20', '4'),\n",
    "('294', '33', '3'),\n",
    "('294', '42', '3'),\n",
    "('294', '44', '4'),\n",
    "('295', '68', '5'),\n",
    "('296', '36', '4'),\n",
    "('297', '90', '5'),\n",
    "('298', '90', '4'),\n",
    "('298', '95', '4'),\n",
    "('299', '90', '4'),\n",
    "('300', '32', '5'),\n",
    "('300', '36', '5'),\n",
    "('300', '95', '5'),\n",
    "('301', '72', '5'),\n",
    "('302', '18', '5'),\n",
    "('302', '69', '5'),\n",
    "('302', '70', '5'),\n",
    "('302', '78', '5'),\n",
    "('303', '36', '5'),\n",
    "('303', '44', '5'),\n",
    "('303', '81', '5'),\n",
    "('304', '29', '5'),\n",
    "('304', '37', '5'),\n",
    "('304', '38', '5'),\n",
    "('304', '76', '5'),\n",
    "('305', '7', '5'),\n",
    "('305', '32', '5'),\n",
    "('306', '22', '5'),\n",
    "('306', '60', '5'),\n",
    "('307', '36', '5'),\n",
    "('307', '95', '4'),\n",
    "('308', '31', '4'),\n",
    "('309', '7', '4'),\n",
    "('309', '32', '4'),\n",
    "('309', '96', '5'),\n",
    "('310', '32', '4'),\n",
    "('310', '44', '4'),\n",
    "('311', '7', '4'),\n",
    "('311', '32', '5'),\n",
    "('312', '6', '3'),\n",
    "('312', '32', '4'),\n",
    "('313', '32', '5'),\n",
    "('313', '44', '5'),\n",
    "('314', '32', '5'),\n",
    "('315', '6', '4'),\n",
    "('315', '32', '4'),\n",
    "('315', '44', '4'),\n",
    "('315', '96', '4'),\n",
    "('316', '3', '2'),\n",
    "('317', '3', '5'),\n",
    "('318', '1', '5'),\n",
    "('318', '3', '5'),\n",
    "('318', '32', '5'),\n",
    "('318', '60', '5'),\n",
    "('319', '3', '5'),\n",
    "('320', '3', '5'),\n",
    "('321', '33', '5'),\n",
    "('322', '42', '4'),\n",
    "('322', '70', '4'),\n",
    "('322', '90', '4'),\n",
    "('322', '96', '4'),\n",
    "('323', '96', '5'),\n",
    "('324', '96', '5'),\n",
    "('325', '96', '5'),\n",
    "('326', '96', '5'),\n",
    "('327', '7', '3'),\n",
    "('328', '7', '5'),\n",
    "('329', '7', '2'),\n",
    "('330', '7', '5'),\n",
    "('331', '7', '5'),\n",
    "('332', '7', '3'),\n",
    "('333', '7', '5'),\n",
    "('333', '32', '5'),\n",
    "('333', '90', '5'),\n",
    "('333', '95', '3'),\n",
    "('334', '7', '5'),\n",
    "('335', '7', '5'),\n",
    "('336', '7', '5'),\n",
    "('337', '7', '1'),\n",
    "('338', '7', '5'),\n",
    "('339', '7', '5'),\n",
    "('339', '32', '5'),\n",
    "('340', '7', '4'),\n",
    "('341', '7', '1'),\n",
    "('342', '50', '5'),\n",
    "('343', '62', '5'),\n",
    "('343', '90', '5'),\n",
    "('344', '1', '4'),\n",
    "('344', '30', '4'),\n",
    "('344', '34', '4'),\n",
    "('345', '7', '4'),\n",
    "('346', '7', '4'),\n",
    "('346', '32', '5'),\n",
    "('347', '7', '5'),\n",
    "('348', '7', '3'),\n",
    "('349', '7', '5'),\n",
    "('350', '13', '5'),\n",
    "('351', '3', '4'),\n",
    "('351', '7', '4'),\n",
    "('352', '90', '5'),\n",
    "('352', '96', '5'),\n",
    "('353', '7', '5'),\n",
    "('353', '32', '4'),\n",
    "('354', '11', '5'),\n",
    "('355', '70', '5'),\n",
    "('355', '96', '5'),\n",
    "('356', '96', '5'),\n",
    "('357', '6', '4'),\n",
    "('357', '96', '4'),\n",
    "('358', '32', '4'),\n",
    "('358', '36', '5'),\n",
    "('358', '95', '5'),\n",
    "('359', '7', '5'),\n",
    "('359', '32', '5'),\n",
    "('359', '36', '5'),\n",
    "('359', '90', '5'),\n",
    "('359', '95', '5'),\n",
    "('360', '7', '5'),\n",
    "('360', '32', '5'),\n",
    "('360', '36', '5'),\n",
    "('360', '44', '5'),\n",
    "('361', '32', '5'),\n",
    "('361', '44', '5'),\n",
    "('362', '32', '4'),\n",
    "('362', '44', '4'),\n",
    "('363', '6', '5'),\n",
    "('364', '6', '5'),\n",
    "('364', '81', '5'),\n",
    "('365', '6', '5'),\n",
    "('366', '6', '5'),\n",
    "('366', '7', '5'),\n",
    "('366', '96', '5'),\n",
    "('367', '6', '5'),\n",
    "('367', '7', '5'),\n",
    "('368', '20', '5'),\n",
    "('369', '68', '5'),\n",
    "('370', '68', '5'),\n",
    "('370', '82', '5'),\n",
    "('371', '18', '4'),\n",
    "('372', '26', '4'),\n",
    "('372', '59', '4'),\n",
    "('372', '69', '5'),\n",
    "('373', '3', '4'),\n",
    "('374', '3', '5'),\n",
    "('374', '64', '5'),\n",
    "('375', '3', '5'),\n",
    "('375', '64', '5'),\n",
    "('376', '3', '5'),\n",
    "('376', '50', '5'),\n",
    "('377', '3', '5'),\n",
    "('378', '3', '5'),\n",
    "('379', '19', '4'),\n",
    "('379', '26', '5'),\n",
    "('379', '59', '4'),\n",
    "('380', '3', '5'),\n",
    "('380', '91', '5'),\n",
    "('381', '36', '5'),\n",
    "('382', '32', '5'),\n",
    "('382', '44', '5'),\n",
    "('382', '90', '5'),\n",
    "('383', '7', '4'),\n",
    "('383', '32', '5'),\n",
    "('383', '36', '5'),\n",
    "('383', '42', '5'),\n",
    "('383', '70', '5'),\n",
    "('383', '90', '5'),\n",
    "('383', '95', '5'),\n",
    "('384', '32', '3'),\n",
    "('385', '7', '4'),\n",
    "('385', '32', '5'),\n",
    "('385', '95', '5'),\n",
    "('386', '32', '4'),\n",
    "('387', '32', '4'),\n",
    "('388', '32', '5'),\n",
    "('388', '95', '5'),\n",
    "('389', '32', '4'),\n",
    "('390', '7', '4'),\n",
    "('390', '32', '4'),\n",
    "('390', '36', '4'),\n",
    "('390', '95', '4'),\n",
    "('391', '20', '3'),\n",
    "('391', '60', '5'),\n",
    "('392', '60', '5'),\n",
    "('393', '3', '5'),\n",
    "('393', '64', '4'),\n",
    "('393', '91', '4'),\n",
    "('394', '3', '5'),\n",
    "('394', '80', '4'),\n",
    "('395', '72', '4'),\n",
    "('396', '98', '4'),\n",
    "('397', '56', '5'),\n",
    "('398', '20', '4'),\n",
    "('399', '7', '4'),\n",
    "('399', '32', '4'),\n",
    "('400', '7', '5'),\n",
    "('400', '32', '5'),\n",
    "('400', '96', '5'),\n",
    "('401', '56', '5'),\n",
    "('402', '70', '4'),\n",
    "('402', '96', '5'),\n",
    "('403', '96', '5'),\n",
    "('404', '96', '3'),\n",
    "('405', '96', '5'),\n",
    "('406', '32', '5'),\n",
    "('407', '47', '4'),\n",
    "('408', '49', '5'),\n",
    "('408', '58', '5'),\n",
    "('409', '90', '5'),\n",
    "('410', '62', '4'),\n",
    "('411', '62', '4'),\n",
    "('412', '1', '4'),\n",
    "('413', '42', '2'),\n",
    "('413', '70', '4'),\n",
    "('414', '7', '5'),\n",
    "('415', '7', '5'),\n",
    "('416', '7', '5'),\n",
    "('417', '7', '5'),\n",
    "('417', '32', '5'),\n",
    "('417', '95', '5'),\n",
    "('418', '7', '5'),\n",
    "('419', '7', '5'),\n",
    "('419', '32', '5'),\n",
    "('420', '7', '5'),\n",
    "('421', '7', '5'),\n",
    "('422', '7', '5'),\n",
    "('423', '7', '4'),\n",
    "('424', '7', '5'),\n",
    "('425', '7', '5'),\n",
    "('425', '32', '5'),\n",
    "('426', '7', '1'),\n",
    "('427', '7', '5'),\n",
    "('428', '7', '5'),\n",
    "('429', '7', '5'),\n",
    "('429', '32', '5'),\n",
    "('430', '7', '5'),\n",
    "('431', '3', '5'),\n",
    "('432', '3', '5'),\n",
    "('432', '64', '5'),\n",
    "('433', '58', '1'),\n",
    "('434', '20', '5'),\n",
    "('435', '7', '5'),\n",
    "('436', '7', '3'),\n",
    "('437', '7', '5'),\n",
    "('438', '7', '5'),\n",
    "('438', '32', '5'),\n",
    "('439', '7', '5'),\n",
    "('439', '32', '4'),\n",
    "('439', '36', '5'),\n",
    "('439', '40', '4'),\n",
    "('439', '95', '5'),\n",
    "('440', '7', '4'),\n",
    "('440', '32', '2'),\n",
    "('441', '7', '4'),\n",
    "('442', '7', '4'),\n",
    "('443', '7', '5'),\n",
    "('443', '32', '5'),\n",
    "('443', '36', '5'),\n",
    "('443', '90', '5'),\n",
    "('443', '95', '5'),\n",
    "('444', '52', '4'),\n",
    "('445', '3', '5'),\n",
    "('446', '7', '5'),\n",
    "('446', '32', '5'),\n",
    "('446', '36', '5'),\n",
    "('446', '90', '5'),\n",
    "('446', '95', '5'),\n",
    "('447', '32', '5'),\n",
    "('448', '1', '4'),\n",
    "('448', '18', '4'),\n",
    "('448', '78', '4'),\n",
    "('449', '6', '5'),\n",
    "('449', '96', '5'),\n",
    "('450', '6', '5'),\n",
    "('450', '7', '5'),\n",
    "('450', '32', '5'),\n",
    "('450', '36', '5'),\n",
    "('450', '70', '5'),\n",
    "('450', '96', '5'),\n",
    "('451', '45', '3'),\n",
    "('451', '50', '3'),\n",
    "('451', '70', '3'),\n",
    "('451', '81', '5'),\n",
    "('451', '96', '5'),\n",
    "('452', '96', '3'),\n",
    "('453', '42', '5'),\n",
    "('453', '70', '5'),\n",
    "('454', '6', '4'),\n",
    "('454', '18', '4'),\n",
    "('454', '42', '3'),\n",
    "('454', '70', '4'),\n",
    "('455', '36', '5'),\n",
    "('455', '95', '5'),\n",
    "('455', '96', '5'),\n",
    "('456', '36', '4'),\n",
    "('457', '7', '5'),\n",
    "('457', '32', '5'),\n",
    "('457', '36', '5'),\n",
    "('457', '44', '5'),\n",
    "('457', '90', '5'),\n",
    "('457', '95', '5'),\n",
    "('458', '7', '5'),\n",
    "('458', '32', '5'),\n",
    "('458', '44', '5'),\n",
    "('459', '6', '5'),\n",
    "('460', '6', '4'),\n",
    "('460', '32', '4'),\n",
    "('460', '36', '4'),\n",
    "('460', '70', '4'),\n",
    "('460', '96', '4'),\n",
    "('461', '36', '5'),\n",
    "('461', '95', '5'),\n",
    "('462', '7', '5'),\n",
    "('462', '32', '4'),\n",
    "('462', '90', '4'),\n",
    "('463', '72', '4'),\n",
    "('463', '90', '4'),\n",
    "('464', '90', '4'),\n",
    "('465', '36', '4'),\n",
    "('465', '44', '4'),\n",
    "('465', '52', '5'),\n",
    "('465', '72', '2'),\n",
    "('465', '95', '4'),\n",
    "('465', '97', '4'),\n",
    "('466', '32', '5'),\n",
    "('466', '36', '5'),\n",
    "('466', '44', '5'),\n",
    "('467', '7', '5'),\n",
    "('467', '32', '5'),\n",
    "('467', '95', '5'),\n",
    "('468', '95', '5'),\n",
    "('469', '95', '5'),\n",
    "('470', '50', '4'),\n",
    "('470', '84', '4'),\n",
    "('471', '22', '4'),\n",
    "('471', '64', '4'),\n",
    "('471', '91', '3'),\n",
    "('472', '96', '5'),\n",
    "('473', '89', '5'),\n",
    "('474', '44', '4'),\n",
    "('475', '90', '4'),\n",
    "('476', '80', '3'),\n",
    "('477', '52', '4'),\n",
    "('477', '56', '3');\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query executed sucessfully\n"
     ]
    }
   ],
   "source": [
    "execute_query(connection,insert_ratings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
